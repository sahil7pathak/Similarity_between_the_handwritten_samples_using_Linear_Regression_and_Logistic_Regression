{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for Logistic Regression on Human Observed Data, Concatenated Features\n",
      "Enter 2 for Logistic Regression on Human Observed Data, Subtracted Features\n",
      "\n",
      "Enter 3 for Logistic Regression on GSC Data, Concatenated Features\n",
      "Enter 4 for Logistic Regression on GSC Data, Subtracted Features\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_x</th>\n",
       "      <th>f2_x</th>\n",
       "      <th>f3_x</th>\n",
       "      <th>f4_x</th>\n",
       "      <th>f5_x</th>\n",
       "      <th>f6_x</th>\n",
       "      <th>f7_x</th>\n",
       "      <th>f8_x</th>\n",
       "      <th>f9_x</th>\n",
       "      <th>f10_x</th>\n",
       "      <th>...</th>\n",
       "      <th>f504_x</th>\n",
       "      <th>f505_x</th>\n",
       "      <th>f506_x</th>\n",
       "      <th>f507_x</th>\n",
       "      <th>f508_x</th>\n",
       "      <th>f509_x</th>\n",
       "      <th>f510_x</th>\n",
       "      <th>f511_x</th>\n",
       "      <th>f512_x</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_x  f2_x  f3_x  f4_x  f5_x  f6_x  f7_x  f8_x  f9_x  f10_x   ...    \\\n",
       "0     0     0     0     0     0     0     0     0     0      0   ...     \n",
       "1     0     1     1     0     1     0     0     1     0      0   ...     \n",
       "2     0     0     0     0     0     0     0     0     0      0   ...     \n",
       "3     0     0     0     0     0     0     0     0     0      0   ...     \n",
       "4     0     1     0     0     0     0     0     0     0      0   ...     \n",
       "\n",
       "   f504_x  f505_x  f506_x  f507_x  f508_x  f509_x  f510_x  f511_x  f512_x  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       1  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "'''The Following Datasets are prepared during the processing part of the datasets in Linear Regression'''\n",
    "\n",
    "a = input(\"Enter 1 for Logistic Regression on Human Observed Data, Concatenated Features\\nEnter 2 for Logistic Regression on Human Observed Data, Subtracted Features\\n\\nEnter 3 for Logistic Regression on GSC Data, Concatenated Features\\nEnter 4 for Logistic Regression on GSC Data, Subtracted Features\\n\")\n",
    "if(a == str(1)):\n",
    "    data = pd.read_csv(\"HOD_concat_dataset_logi.csv\")\n",
    "    M = 18\n",
    "elif(a == str(2)):\n",
    "    data = pd.read_csv(\"HOD_sub_dataset_logi.csv\")\n",
    "    M = 9\n",
    "elif(a == str(3)):\n",
    "    data = pd.read_csv(\"GSC_concat_dataset_logi.csv\")\n",
    "    M = 1024\n",
    "elif(a == str(4)):\n",
    "    data = pd.read_csv(\"GSC_sub_dataset_logi.csv\")  \n",
    "    M = 512\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  (114450, 512)\n",
      "Training Target:  (114450, 1)\n",
      "Validation Data:  (14306, 512)\n",
      "Validation Target:  (14306, 1)\n",
      "Testing Data:  (14305, 512)\n",
      "Testing Target:  (14305, 1)\n"
     ]
    }
   ],
   "source": [
    "rows = data.shape[0]\n",
    "cols = data.shape[1]\n",
    "\n",
    "#Partitioning the Data\n",
    "TrainPercent = 80\n",
    "ValPercent = 10\n",
    "TestPercent = 10\n",
    "\n",
    "#Training Set\n",
    "train_X = data.iloc[0:int(math.ceil(data.shape[0]*0.01*TrainPercent)):,0:cols-1]\n",
    "train_count= int(math.ceil(data.shape[0]*0.01*TrainPercent))\n",
    "train_Y = data.iloc[0:int(math.ceil(data.shape[0]*0.01*TrainPercent)):,cols-1:cols]\n",
    "print(\"Training Data: \",train_X.shape)\n",
    "print(\"Training Target: \",train_Y.shape)\n",
    "\n",
    "#Validation set\n",
    "val_size = int(math.ceil(data.shape[0]*ValPercent*0.01))\n",
    "val_end = train_count + val_size\n",
    "val_X = data.iloc[train_count+1:val_end,0:cols-1]\n",
    "val_Y = data.iloc[train_count+1:val_end,cols-1:cols]\n",
    "print(\"Validation Data: \",val_X.shape)\n",
    "print(\"Validation Target: \",val_Y.shape)\n",
    "\n",
    "#Testing set\n",
    "test_X = data.iloc[val_end:data.shape[0],0:cols-1]\n",
    "test_Y = data.iloc[val_end:data.shape[0],cols-1:cols]\n",
    "print(\"Testing Data: \",test_X.shape)\n",
    "print(\"Testing Target: \",test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(train_X.values)\n",
    "train_Y = np.array(train_Y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def cost(theta, X, Y):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    Y = np.matrix(Y)\n",
    "    term1 = np.multiply(-Y, np.log(sigmoid(X * theta.T)))\n",
    "    term2 = np.multiply((1-Y), np.log(1 - sigmoid(X * theta.T)))\n",
    "    return np.sum(term1 - term2) / (len(X))\n",
    "\n",
    "def evaluate_gradient(theta, X, Y):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    Y = np.matrix(Y)\n",
    "    \n",
    "    parameters =  int(theta.ravel().shape[1])\n",
    "    grad = np.zeros(parameters)\n",
    "    \n",
    "    error = sigmoid(X*theta.T) - Y\n",
    "    \n",
    "    for i in range(parameters):\n",
    "        term = np.multiply(error, X[:,i])\n",
    "        grad[i] = np.sum(term) / len(X)\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def accuracy(predicted_labels, actual_labels):\n",
    "    counter = 0.0\n",
    "    for i in range (0,predicted_labels.shape[0]):\n",
    "        if(int(np.around(predicted_labels[i], 0)) == actual_labels[i]):\n",
    "            counter+=1\n",
    "    accuracy = (float((counter*100))/float(len(predicted_labels)))\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training using Gradient Descent Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights: \n",
      " [-2.48293126e-02 -1.77772520e-03 -2.18474585e-03 -1.05123983e-02\n",
      " -1.18584138e-02 -1.92585005e-04 -1.46151516e-02  9.61806794e-03\n",
      "  5.91766342e-03 -6.66324489e-05 -1.27005280e-02 -5.70585751e-03\n",
      " -2.26281215e-02  1.35035664e-02  6.20653959e-03  1.65989362e-03\n",
      " -1.82255355e-02 -2.05525644e-02 -1.19313141e-03 -3.66968918e-03\n",
      " -8.96834434e-03 -2.55678742e-03 -1.52559559e-02 -7.77075425e-03\n",
      " -2.12679027e-03  1.40266792e-02 -5.22906136e-04  7.03367582e-03\n",
      "  1.15882609e-02  4.29671558e-04  2.51346784e-03 -7.39426803e-03\n",
      "  2.60184551e-03  6.60037037e-04  4.37899014e-03 -1.18737352e-02\n",
      " -1.58319866e-02 -1.14707954e-02  1.19963337e-02  1.15043998e-02\n",
      "  7.93528662e-03  4.35257705e-03 -2.07042714e-02  3.70510366e-03\n",
      "  8.88324529e-03  3.46653739e-03 -6.08404340e-04  1.06790620e-02\n",
      "  3.76301894e-03 -3.39863557e-03 -2.31736212e-03 -1.40336321e-02\n",
      "  1.19812690e-02 -1.97449505e-03  8.42488567e-03 -7.91730028e-03\n",
      "  1.55890534e-02 -3.36949331e-02 -1.49776719e-02 -3.15057933e-02\n",
      " -3.13808829e-03 -1.70506709e-02 -7.44811913e-03  1.07489016e-02\n",
      "  1.68934440e-03 -5.74847481e-03  6.20468700e-03 -5.23645885e-05\n",
      "  4.12603190e-03 -9.06553958e-03 -7.64435263e-03 -2.64690971e-02\n",
      " -1.05396857e-02  1.76290680e-03 -1.09417001e-03  1.21919524e-02\n",
      "  1.14607048e-02 -1.03828500e-03  7.46029611e-03  1.57326675e-02\n",
      "  6.07995554e-03  2.09108759e-03  6.60130664e-03 -5.26147460e-03\n",
      "  7.43642810e-03  1.18954010e-02 -6.21408293e-04  1.20477364e-03\n",
      " -8.24994673e-04  2.15705386e-03 -8.91845120e-03 -3.44939308e-03\n",
      " -6.89435618e-03  2.00874963e-02 -7.28398629e-04  9.98531084e-03\n",
      "  5.17899052e-03 -1.73123910e-02  2.67737785e-03  2.23338872e-02\n",
      " -2.69449985e-03 -7.21203989e-03  1.21359381e-02  1.96475526e-03\n",
      "  4.63479681e-03 -8.81119695e-03 -2.88752727e-03 -7.95313036e-03\n",
      " -4.28847887e-03 -1.10506979e-02 -6.36461650e-03 -4.21483994e-03\n",
      "  6.96700472e-03 -1.30754363e-02  7.89601344e-03  3.21738214e-06\n",
      "  1.95980107e-02 -6.58976583e-03 -4.16457772e-04  6.19225760e-03\n",
      "  3.63197915e-03 -1.16107710e-02 -5.69505754e-03  2.69219634e-03\n",
      "  9.08750358e-03  6.63024705e-03  5.14571712e-03 -8.04654452e-03\n",
      "  1.30989516e-03 -3.39402711e-05  5.52936380e-03 -3.89355669e-03\n",
      " -5.51919281e-03 -4.13271709e-03 -2.09106306e-02 -2.23372724e-02\n",
      " -2.87712142e-04 -2.79035578e-03  2.10434016e-02 -2.74202769e-03\n",
      "  6.54866976e-04  1.13004920e-02 -2.90132265e-03 -2.59079457e-02\n",
      "  6.60866125e-03  2.14633657e-02  1.40320911e-02  1.31692422e-02\n",
      "  4.35689136e-03 -1.75969830e-02  1.27495135e-02  1.28032946e-02\n",
      " -2.64379919e-03  1.62130188e-02 -4.72319735e-03  4.90211018e-03\n",
      " -3.62244318e-03  9.91550342e-03  2.10174200e-02 -7.65834386e-03\n",
      "  2.40531794e-03  1.82661717e-03  2.71005348e-03 -2.32312615e-03\n",
      " -3.42647688e-03  3.73930536e-02  4.72778700e-03 -1.23583955e-02\n",
      " -7.03447844e-03  9.87500329e-03  4.17965278e-03 -5.56729136e-03\n",
      " -6.26877094e-05 -2.49649316e-02 -2.38729312e-03 -5.65896995e-03\n",
      " -7.58355146e-03 -2.24337080e-03  2.28371135e-02 -1.16290397e-02\n",
      " -1.66536704e-02 -7.99586544e-03 -6.51010098e-03 -3.45009372e-02\n",
      " -8.56185827e-03 -1.24012462e-02 -1.32542913e-02 -5.79257271e-03\n",
      "  1.26652395e-02 -2.09668615e-02 -1.26828979e-02 -9.11497467e-03\n",
      " -3.01782643e-03 -4.65881799e-03 -2.50058466e-03 -8.08744804e-03\n",
      " -5.30665800e-03 -8.53395397e-03  1.43146434e-04 -6.41495634e-03\n",
      " -1.32721363e-02 -1.09706103e-02 -2.95969865e-03  4.48567749e-04\n",
      " -2.96354574e-03 -5.08987434e-03 -1.12319046e-02 -3.33284116e-03\n",
      " -3.26231429e-03 -7.14512951e-03  5.44765499e-03 -2.63555757e-03\n",
      " -3.99239466e-03 -4.05621233e-03 -2.96562594e-03  2.46202174e-04\n",
      " -9.15629412e-03 -8.97584781e-03  1.46406936e-03  4.69601587e-03\n",
      "  9.17277074e-03  2.87549322e-04 -9.12220672e-03 -3.71780276e-03\n",
      " -4.40109126e-03 -9.03308218e-04  1.27749637e-03 -1.43709357e-03\n",
      " -1.40593905e-02 -1.86987865e-02 -2.19644556e-02 -3.47736417e-03\n",
      "  1.45830300e-02  6.14182081e-03  7.22805748e-03  1.52994763e-02\n",
      "  1.44898363e-02  8.13392844e-03  3.29427737e-03  7.28411062e-04\n",
      "  7.96578338e-03  8.14531665e-03  1.26057237e-03  5.34919964e-03\n",
      " -7.02433246e-03  6.35306853e-03  2.25502961e-02  2.35382007e-02\n",
      " -2.38567668e-02 -7.19251660e-03 -9.51662672e-04 -6.35806842e-05\n",
      "  7.88180452e-03 -2.74490803e-03  1.57183494e-02 -3.77926411e-03\n",
      "  1.01243959e-02  8.85895536e-03  1.87088438e-02  8.89028262e-03\n",
      " -1.38019227e-02 -2.75883252e-02 -2.56195239e-03  3.04863445e-04\n",
      " -1.67402712e-02 -2.96941943e-03 -1.35956287e-02  3.95696705e-03\n",
      "  1.60103942e-02  2.61456316e-03  1.69050475e-03  1.55696091e-03\n",
      " -2.75974401e-02 -7.89425277e-03  4.23892670e-03  6.27189274e-04\n",
      " -6.84050323e-03 -3.20603553e-03  6.90784959e-03  6.83551749e-03\n",
      " -2.94742158e-02 -6.24430084e-03 -2.53760344e-03 -3.35388221e-03\n",
      " -6.32026719e-03 -2.00424033e-03  2.84860966e-04  3.57298318e-03\n",
      " -1.89041800e-03  3.25279891e-03 -9.49666673e-03  5.68496937e-03\n",
      "  1.80365508e-02 -3.60037573e-03 -3.61366038e-03  1.09910252e-05\n",
      " -7.11969114e-04  3.58741604e-03 -1.08948077e-02  1.13543353e-03\n",
      "  6.50104714e-03  6.31185082e-03 -4.03756401e-03  1.08692938e-02\n",
      " -2.72600451e-03  8.26388552e-03 -7.58235561e-03  9.86835239e-03\n",
      "  1.94431580e-02  5.93845034e-03  1.58567978e-03  3.75278002e-03\n",
      " -1.31367650e-02  1.59781711e-02  5.51481946e-03  1.35752778e-02\n",
      "  6.42461642e-03  8.29285830e-03 -1.12496473e-02  5.26908918e-03\n",
      "  6.28437335e-04 -7.08140533e-03 -1.53175085e-02  3.53397219e-03\n",
      "  6.08168995e-03 -9.87461449e-03 -9.85383071e-04  2.10669277e-03\n",
      " -2.37921707e-02  2.70742746e-03  1.57902783e-03 -1.45753359e-02\n",
      "  6.77135323e-03  5.42563521e-03 -2.03852474e-02 -6.87286748e-03\n",
      "  2.46803746e-02  2.88307868e-03  4.95890323e-03 -4.51443830e-03\n",
      "  3.00562878e-02  3.23403613e-03  1.50568703e-02  7.03344789e-03\n",
      " -1.07320398e-02  2.59989631e-03 -2.07245612e-02 -7.44959757e-03\n",
      "  5.02851483e-03 -3.33258857e-03  1.79611697e-02  2.66458958e-03\n",
      "  1.10444028e-02 -1.30129794e-02 -1.05130502e-02 -5.77438700e-03\n",
      "  1.54210032e-03 -1.36355301e-03 -8.42569293e-04 -3.17127873e-03\n",
      "  3.69408962e-04 -1.31222323e-02  1.72617065e-02 -1.65306364e-02\n",
      "  1.94392415e-02  1.10600671e-03  2.20092145e-04  2.11421473e-03\n",
      " -7.49254473e-03 -1.79958745e-02 -1.32422266e-02  2.24194433e-04\n",
      "  1.06350042e-02  7.73516787e-04  3.25842639e-03 -3.36985037e-03\n",
      "  6.52678965e-03  5.86803423e-03  1.01301880e-02  8.35555119e-03\n",
      " -2.84891458e-02 -7.46379380e-03 -1.41881746e-02  3.74516292e-03\n",
      "  2.48164878e-03 -4.36127650e-03  6.78837945e-04 -1.17478726e-02\n",
      " -8.81889847e-03 -5.79732009e-03 -1.32029392e-02 -9.88340501e-03\n",
      "  2.07867254e-04 -2.05430687e-03 -1.87638452e-03 -2.48393600e-03\n",
      " -1.49887273e-02  5.01079712e-03  6.80480053e-03  1.58817167e-02\n",
      " -1.42809825e-03 -6.83147382e-03  8.38452395e-04 -1.99597883e-02\n",
      "  5.35573369e-03 -6.49049835e-03 -4.45654080e-03 -3.88471601e-03\n",
      " -9.59998453e-03 -7.91884442e-03 -3.49888994e-03  2.87075474e-03\n",
      "  1.98250484e-03 -6.09143522e-04  1.05816059e-02  1.97110345e-03\n",
      "  1.37674894e-03 -8.23815470e-03 -6.87658530e-03 -1.18542655e-02\n",
      " -6.05481731e-03 -4.45802602e-04 -8.92528628e-03 -2.40854197e-03\n",
      " -7.82105022e-03  2.66982753e-03  4.56603419e-03  5.24712568e-04\n",
      " -1.82030649e-02  8.22655734e-04  4.27863347e-03  9.60903378e-03\n",
      " -6.80789771e-03 -1.08028155e-02  9.83205333e-03  1.65194597e-03\n",
      " -5.43675067e-03  8.57130198e-03  1.53324670e-02  1.10866571e-03\n",
      " -1.41166410e-02  5.81405249e-03 -1.35953693e-03  1.63523527e-03\n",
      "  1.13084827e-02  1.17412269e-03  4.91700303e-03  4.97061707e-03\n",
      " -2.22551851e-04 -2.63615677e-04  0.00000000e+00 -9.45483929e-03\n",
      "  0.00000000e+00  6.03749840e-04 -2.70121674e-03  4.56237177e-03\n",
      "  0.00000000e+00  1.96703702e-04 -7.74006915e-03  3.69874550e-03\n",
      "  7.23570637e-05  2.37277171e-04  2.07959406e-04 -1.86087349e-02\n",
      "  7.28781488e-04 -1.05915261e-02 -1.15738619e-02 -6.25284319e-03\n",
      "  1.11473004e-02 -1.05577243e-02 -7.81224212e-03  1.12637682e-02\n",
      "  2.07535261e-02 -1.81279231e-02 -9.25819234e-03  2.21575006e-03\n",
      "  2.73247575e-02 -8.30313118e-04 -1.31593304e-02 -3.16791430e-02\n",
      "  1.31295854e-04 -4.64137057e-03 -1.87828975e-03  8.45816627e-04\n",
      "  2.19636404e-03  1.28373981e-02  1.33159100e-02  1.62307599e-02\n",
      " -1.43673543e-02  1.76691784e-02 -2.85884482e-03  1.73664229e-02\n",
      "  5.92532695e-05 -5.55991852e-03 -5.04926372e-03 -4.74312141e-03\n",
      " -4.88133022e-04 -1.21637299e-03  3.35271722e-03  6.67127975e-03\n",
      "  2.20088128e-03 -1.62721999e-03  4.32818561e-04  5.02082917e-03\n",
      "  4.86538772e-04 -2.62554199e-03  3.99180308e-03  5.86355294e-03\n",
      " -1.67169005e-03 -5.52045782e-04 -7.52017720e-04 -5.67986662e-04]\n",
      "Final Training Cost:  0.6819662492893548\n"
     ]
    }
   ],
   "source": [
    "theta_now = np.zeros(M)\n",
    "theta_now = np.dot(55, theta_now)\n",
    "lr = 0.01\n",
    "Acc = []\n",
    "\n",
    "for epochs in range(500):\n",
    "    \n",
    "    delta_theta = evaluate_gradient(theta_now, train_X, train_Y)\n",
    "    cost1 = cost(theta_now, train_X, train_Y)\n",
    "    theta_next = theta_now - (lr*delta_theta)\n",
    "    theta_now = theta_next\n",
    "    \n",
    "    z1 = np.dot(theta_next, (np.transpose(train_X)))\n",
    "    train_out = sigmoid(z1)\n",
    "    val = accuracy(train_out, train_Y)\n",
    "    Acc.append(val)\n",
    "    \n",
    "\n",
    "print(\"Updated Weights: \\n\",theta_now)\n",
    "print(\"Final Training Cost: \",cost1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Validation and Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 58.23853\n",
      "Validation Cost:  0.6822456193818929\n",
      "Validation Accuracy:  58.12945617223543\n",
      "Testing Cost:  0.6830839364602043\n",
      "Testing Accuracy:  57.154840964697655\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \" + str(np.around(max(Acc),5)))\n",
    "z2 = np.dot(theta_now, (np.transpose(val_X)))\n",
    "val_out = sigmoid(z2)\n",
    "val_Y = np.matrix(val_Y)\n",
    "vald = accuracy(val_out, val_Y)\n",
    "val_cost = cost(theta_now, val_X, val_Y)\n",
    "print(\"Validation Cost: \",val_cost)\n",
    "print(\"Validation Accuracy: \",vald)\n",
    "\n",
    "z3 = np.dot(theta_now, (np.transpose(test_X)))\n",
    "test_out = sigmoid(z3)\n",
    "test_Y = np.matrix(test_Y)\n",
    "test = accuracy(test_out, test_Y)\n",
    "test_cost = cost(theta_now, test_X, test_Y)\n",
    "print(\"Testing Cost: \",test_cost)\n",
    "print(\"Testing Accuracy: \",test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33503, 23709],\n",
       "       [24546, 32692]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(train_Y,np.around(train_out,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4154, 3016],\n",
       "       [3024, 4112]], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(val_Y,np.around(val_out,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4094, 3055],\n",
       "       [3094, 4062]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_Y,np.around(test_out,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.579635112852609\n",
      "0.5711590202313148\n"
     ]
    }
   ],
   "source": [
    "'''Calculating the Precision Score, The precision is intuitively the ability of the classifier not to label \n",
    "as positive a sample that is negative. &  The recall is intuitively the ability of the classifier to find all the \n",
    "positive samples.\n",
    "The best value is 1 and the worst value is 0 for both.'''\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "print(precision_score(train_Y, train_out.round(), average='binary'))\n",
    "print(recall_score(train_Y, train_out.round(), average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5768799102132436\n",
      "0.5762331838565022\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(val_Y, val_out.round(), average='binary'))\n",
    "print(recall_score(val_Y, val_out.round(), average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5707461008852044\n",
      "0.5676355505869201\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(test_Y, test_out.round(), average='binary')) \n",
    "print(recall_score(test_Y, test_out.round(), average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
